{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10708970,"sourceType":"datasetVersion","datasetId":6637063}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:26:11.603472Z","iopub.execute_input":"2025-04-01T10:26:11.603913Z","iopub.status.idle":"2025-04-01T10:26:11.938236Z","shell.execute_reply.started":"2025-04-01T10:26:11.603876Z","shell.execute_reply":"2025-04-01T10:26:11.937367Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/fer-ck-augmentedfer/ferckaugmentedfer.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom torchvision import models\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport os\nimport time\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:26:13.026879Z","iopub.execute_input":"2025-04-01T10:26:13.027424Z","iopub.status.idle":"2025-04-01T10:26:19.131179Z","shell.execute_reply.started":"2025-04-01T10:26:13.027389Z","shell.execute_reply":"2025-04-01T10:26:19.130422Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:26:19.132260Z","iopub.execute_input":"2025-04-01T10:26:19.132601Z","iopub.status.idle":"2025-04-01T10:26:19.186973Z","shell.execute_reply.started":"2025-04-01T10:26:19.132580Z","shell.execute_reply":"2025-04-01T10:26:19.186240Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Define your transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize to fit standard models\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:26:19.188450Z","iopub.execute_input":"2025-04-01T10:26:19.188727Z","iopub.status.idle":"2025-04-01T10:26:19.203874Z","shell.execute_reply.started":"2025-04-01T10:26:19.188706Z","shell.execute_reply":"2025-04-01T10:26:19.203217Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class EmotionDataset(Dataset):\n    def __init__(self, csv_file, transform=None):\n        # Load the CSV file\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        # Get the pixel values and reshape them into an image\n        pixels = self.data.iloc[idx][' pixels'].split()\n        pixels = np.array([int(pixel) for pixel in pixels], dtype=np.uint8)\n        image = pixels.reshape(48, 48)\n        \n        # Convert grayscale to RGB by duplicating channels (EfficientNet expects RGB)\n        image = np.stack((image,) * 3, axis=-1)\n        image = Image.fromarray(image)\n        \n        # Get the label\n        label = self.data.iloc[idx]['emotion']\n        \n        if self.transform:\n            image = self.transform(image)\n            \n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:33:05.775486Z","iopub.execute_input":"2025-04-01T10:33:05.775861Z","iopub.status.idle":"2025-04-01T10:33:05.782445Z","shell.execute_reply.started":"2025-04-01T10:33:05.775834Z","shell.execute_reply":"2025-04-01T10:33:05.781654Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def create_dataloaders(dataset, batch_size=32):\n    # Split into train, validation, and test sets (70%, 10%, 20%)\n    train_size = int(0.7 * len(dataset))\n    val_size = int(0.1 * len(dataset))\n    test_size = len(dataset) - train_size - val_size\n    \n    train_data, val_data, test_data = random_split(\n        dataset, [train_size, val_size, test_size], \n        generator=torch.Generator().manual_seed(42)  # For reproducibility\n    )\n    \n    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4)\n    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)\n    \n    return train_loader, val_loader, test_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:33:17.250269Z","iopub.execute_input":"2025-04-01T10:33:17.250588Z","iopub.status.idle":"2025-04-01T10:33:17.255547Z","shell.execute_reply.started":"2025-04-01T10:33:17.250563Z","shell.execute_reply":"2025-04-01T10:33:17.254732Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def evaluate_model(model, data_loader, criterion):\n    model.eval()\n    running_loss = 0.0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for inputs, labels in tqdm(data_loader, desc=\"Evaluating\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item() * inputs.size(0)\n            \n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    # Calculate metrics\n    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n    \n    epoch_loss = running_loss / len(data_loader.dataset)\n    \n    return epoch_loss, accuracy, precision, recall, f1, all_preds, all_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:33:19.974468Z","iopub.execute_input":"2025-04-01T10:33:19.974817Z","iopub.status.idle":"2025-04-01T10:33:19.981055Z","shell.execute_reply.started":"2025-04-01T10:33:19.974792Z","shell.execute_reply":"2025-04-01T10:33:19.980265Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, test_loader, criterion, optimizer, scheduler, max_epochs=20, save_every=5):\n    start_time = time.time()\n    \n    # Create directory for saving models\n    os.makedirs('model_checkpoints', exist_ok=True)\n    \n    # For tracking performance\n    history = {\n        'train_loss': [], 'train_acc': [], 'train_precision': [], 'train_recall': [], \n        'val_loss': [], 'val_acc': [], 'val_precision': [], 'val_recall': [],\n        'test_loss': [], 'test_acc': [], 'test_precision': [], 'test_recall': []\n    }\n    \n    # Metrics at key epochs (10, 15, 20)\n    key_metrics = {10: {}, 15: {}, 20: {}}\n    \n    for epoch in range(1, max_epochs + 1):\n        print(f\"\\nEpoch {epoch}/{max_epochs}\")\n        print('-' * 10)\n        \n        # Training phase\n        model.train()\n        running_loss = 0.0\n        all_train_preds = []\n        all_train_labels = []\n        \n        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            # Zero the parameter gradients\n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            # Backward pass and optimize\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item() * inputs.size(0)\n            \n            _, preds = torch.max(outputs, 1)\n            all_train_preds.extend(preds.cpu().numpy())\n            all_train_labels.extend(labels.cpu().numpy())\n        \n        # Step the scheduler\n        if scheduler:\n            scheduler.step()\n            \n        # Calculate train metrics\n        train_loss = running_loss / len(train_loader.dataset)\n        train_acc = np.mean(np.array(all_train_preds) == np.array(all_train_labels))\n        train_precision = precision_score(all_train_labels, all_train_preds, average='weighted', zero_division=0)\n        train_recall = recall_score(all_train_labels, all_train_preds, average='weighted', zero_division=0)\n        \n        # Evaluate on validation set\n        val_loss, val_acc, val_precision, val_recall, val_f1, _, _ = evaluate_model(model, val_loader, criterion)\n        \n        # Evaluate on test set\n        test_loss, test_acc, test_precision, test_recall, test_f1, _, _ = evaluate_model(model, test_loader, criterion)\n        \n        # Save metrics to history\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n        history['train_precision'].append(train_precision)\n        history['train_recall'].append(train_recall)\n        \n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        history['val_precision'].append(val_precision)\n        history['val_recall'].append(val_recall)\n        \n        history['test_loss'].append(test_loss)\n        history['test_acc'].append(test_acc)\n        history['test_precision'].append(test_precision)\n        history['test_recall'].append(test_recall)\n        \n        # Print metrics\n        print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}\")\n        print(f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}\")\n        print(f\"Test Loss: {test_loss:.4f}, Acc: {test_acc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")\n        \n        # Save model if it's one of the key epochs (10, 15, 20) or at save_every interval\n        if epoch in [10, 15, 20] or epoch % save_every == 0:\n            checkpoint_path = f\"model_checkpoints/efficientnet_emotion_epoch_{epoch}.pth\"\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'train_loss': train_loss,\n                'val_loss': val_loss,\n                'test_loss': test_loss,\n            }, checkpoint_path)\n            print(f\"Model saved to {checkpoint_path}\")\n        \n        # Store key metrics\n        if epoch in key_metrics:\n            key_metrics[epoch] = {\n                'val_acc': val_acc,\n                'val_precision': val_precision,\n                'val_recall': val_recall,\n                'test_acc': test_acc,\n                'test_precision': test_precision,\n                'test_recall': test_recall\n            }\n    \n    time_elapsed = time.time() - start_time\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    \n    # Print key metrics\n    print(\"\\nMetrics at key epochs:\")\n    for epoch in [10, 15, 20]:\n        if epoch in key_metrics:\n            print(f\"\\nEpoch {epoch}:\")\n            print(f\"Validation - Accuracy: {key_metrics[epoch]['val_acc']:.4f}, Precision: {key_metrics[epoch]['val_precision']:.4f}, Recall: {key_metrics[epoch]['val_recall']:.4f}\")\n            print(f\"Test - Accuracy: {key_metrics[epoch]['test_acc']:.4f}, Precision: {key_metrics[epoch]['test_precision']:.4f}, Recall: {key_metrics[epoch]['test_recall']:.4f}\")\n    \n    return model, history, key_metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:33:22.238276Z","iopub.execute_input":"2025-04-01T10:33:22.238576Z","iopub.status.idle":"2025-04-01T10:33:22.252462Z","shell.execute_reply.started":"2025-04-01T10:33:22.238554Z","shell.execute_reply":"2025-04-01T10:33:22.251482Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Main execution\nif __name__ == \"__main__\":\n    # Parameters\n    BATCH_SIZE = 32\n    LEARNING_RATE = 0.001\n    MAX_EPOCHS = 20\n    NUM_CLASSES = 7  # Adjust based on your emotion classes (typically 7 for FER)\n    \n    # Load dataset\n    dataset = EmotionDataset(\n        csv_file=\"/kaggle/input/fer-ck-augmentedfer/ferckaugmentedfer.csv\", \n        transform=transform\n    )\n    \n    # Create dataloaders\n    train_loader, val_loader, test_loader = create_dataloaders(dataset, batch_size=BATCH_SIZE)\n    \n    # Load pre-trained EfficientNetB0\n    model = models.efficientnet_b0(pretrained=True)\n    \n    # Modify the classifier for our number of classes\n    in_features = model.classifier[1].in_features\n    model.classifier[1] = nn.Linear(in_features, NUM_CLASSES)\n    \n    # Move model to device\n    model = model.to(device)\n    \n    # Loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    \n    # Learning rate scheduler\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n    \n    # Train the model\n    model, history, key_metrics = train_model(\n        model, train_loader, val_loader, test_loader, \n        criterion, optimizer, scheduler, \n        max_epochs=MAX_EPOCHS, save_every=5\n    )\n    \n    # Save final model\n    torch.save(model.state_dict(), '/kaggle/working/efficientnet_emotion_final.pth')\n    \n    # Save metrics history\n    metrics_df = pd.DataFrame(history)\n    metrics_df.to_csv('/kaggle/working/training_metrics_history.csv', index=False)\n    \n    print(\"Training completed and metrics saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:33:29.429053Z","iopub.execute_input":"2025-04-01T10:33:29.429357Z","iopub.status.idle":"2025-04-01T11:51:50.317257Z","shell.execute_reply.started":"2025-04-01T10:33:29.429334Z","shell.execute_reply":"2025-04-01T11:51:50.316212Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:22<00:00,  8.12it/s]\nEvaluating: 100%|██████████| 235/235 [00:12<00:00, 19.19it/s]\nEvaluating: 100%|██████████| 470/470 [00:21<00:00, 21.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0626, Acc: 0.5998, Precision: 0.5934, Recall: 0.5998\nVal Loss: 0.9028, Acc: 0.6565, Precision: 0.6630, Recall: 0.6565\nTest Loss: 0.9336, Acc: 0.6492, Precision: 0.6579, Recall: 0.6492\n\nEpoch 2/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.18it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 21.29it/s]\nEvaluating: 100%|██████████| 470/470 [00:22<00:00, 21.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8413, Acc: 0.6902, Precision: 0.6873, Recall: 0.6902\nVal Loss: 0.8033, Acc: 0.7033, Precision: 0.7175, Recall: 0.7033\nTest Loss: 0.8235, Acc: 0.6929, Precision: 0.7055, Recall: 0.6929\n\nEpoch 3/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.19it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 19.97it/s]\nEvaluating: 100%|██████████| 470/470 [00:22<00:00, 21.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7057, Acc: 0.7441, Precision: 0.7420, Recall: 0.7441\nVal Loss: 0.7191, Acc: 0.7402, Precision: 0.7517, Recall: 0.7402\nTest Loss: 0.7367, Acc: 0.7351, Precision: 0.7471, Recall: 0.7351\n\nEpoch 4/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.19it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 19.98it/s]\nEvaluating: 100%|██████████| 470/470 [00:21<00:00, 21.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5691, Acc: 0.7955, Precision: 0.7947, Recall: 0.7955\nVal Loss: 0.6544, Acc: 0.7663, Precision: 0.7793, Recall: 0.7663\nTest Loss: 0.6520, Acc: 0.7676, Precision: 0.7788, Recall: 0.7676\n\nEpoch 5/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.18it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 20.35it/s]\nEvaluating: 100%|██████████| 470/470 [00:22<00:00, 21.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4502, Acc: 0.8399, Precision: 0.8394, Recall: 0.8399\nVal Loss: 0.5985, Acc: 0.8071, Precision: 0.8109, Recall: 0.8071\nTest Loss: 0.6083, Acc: 0.7992, Precision: 0.8012, Recall: 0.7992\nModel saved to model_checkpoints/efficientnet_emotion_epoch_5.pth\n\nEpoch 6/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.18it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 19.87it/s]\nEvaluating: 100%|██████████| 470/470 [00:23<00:00, 19.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3516, Acc: 0.8764, Precision: 0.8761, Recall: 0.8764\nVal Loss: 0.5587, Acc: 0.8239, Precision: 0.8245, Recall: 0.8239\nTest Loss: 0.5741, Acc: 0.8222, Precision: 0.8230, Recall: 0.8222\n\nEpoch 7/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.19it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 20.54it/s]\nEvaluating: 100%|██████████| 470/470 [00:21<00:00, 21.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2830, Acc: 0.9029, Precision: 0.9028, Recall: 0.9029\nVal Loss: 0.5490, Acc: 0.8404, Precision: 0.8430, Recall: 0.8404\nTest Loss: 0.5685, Acc: 0.8347, Precision: 0.8383, Recall: 0.8347\n\nEpoch 8/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.19it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 21.14it/s]\nEvaluating: 100%|██████████| 470/470 [00:22<00:00, 21.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1112, Acc: 0.9642, Precision: 0.9642, Recall: 0.9642\nVal Loss: 0.4850, Acc: 0.8901, Precision: 0.8915, Recall: 0.8901\nTest Loss: 0.4875, Acc: 0.8896, Precision: 0.8905, Recall: 0.8896\n\nEpoch 9/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:21<00:00,  8.17it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 20.27it/s]\nEvaluating: 100%|██████████| 470/470 [00:22<00:00, 21.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0518, Acc: 0.9838, Precision: 0.9838, Recall: 0.9838\nVal Loss: 0.5205, Acc: 0.8967, Precision: 0.8970, Recall: 0.8967\nTest Loss: 0.5200, Acc: 0.8982, Precision: 0.8981, Recall: 0.8982\n\nEpoch 10/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.18it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 20.15it/s]\nEvaluating: 100%|██████████| 470/470 [00:22<00:00, 21.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0351, Acc: 0.9893, Precision: 0.9893, Recall: 0.9893\nVal Loss: 0.5413, Acc: 0.9006, Precision: 0.9007, Recall: 0.9006\nTest Loss: 0.5464, Acc: 0.8996, Precision: 0.8995, Recall: 0.8996\nModel saved to model_checkpoints/efficientnet_emotion_epoch_10.pth\n\nEpoch 11/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.18it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 21.31it/s]\nEvaluating: 100%|██████████| 470/470 [00:22<00:00, 21.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0288, Acc: 0.9908, Precision: 0.9908, Recall: 0.9908\nVal Loss: 0.5752, Acc: 0.9022, Precision: 0.9025, Recall: 0.9022\nTest Loss: 0.5771, Acc: 0.9012, Precision: 0.9012, Recall: 0.9012\n\nEpoch 12/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:21<00:00,  8.17it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 20.24it/s]\nEvaluating: 100%|██████████| 470/470 [00:21<00:00, 21.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0239, Acc: 0.9925, Precision: 0.9925, Recall: 0.9925\nVal Loss: 0.6010, Acc: 0.9023, Precision: 0.9025, Recall: 0.9023\nTest Loss: 0.5936, Acc: 0.9030, Precision: 0.9028, Recall: 0.9030\n\nEpoch 13/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.20it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 20.15it/s]\nEvaluating: 100%|██████████| 470/470 [00:22<00:00, 21.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0226, Acc: 0.9925, Precision: 0.9925, Recall: 0.9925\nVal Loss: 0.6007, Acc: 0.9010, Precision: 0.9015, Recall: 0.9010\nTest Loss: 0.5989, Acc: 0.9047, Precision: 0.9049, Recall: 0.9047\n\nEpoch 14/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.19it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 20.00it/s]\nEvaluating: 100%|██████████| 470/470 [00:21<00:00, 21.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0183, Acc: 0.9941, Precision: 0.9941, Recall: 0.9941\nVal Loss: 0.6284, Acc: 0.9005, Precision: 0.9008, Recall: 0.9005\nTest Loss: 0.6201, Acc: 0.9043, Precision: 0.9043, Recall: 0.9043\n\nEpoch 15/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.18it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 20.82it/s]\nEvaluating: 100%|██████████| 470/470 [00:21<00:00, 21.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0155, Acc: 0.9948, Precision: 0.9948, Recall: 0.9948\nVal Loss: 0.6255, Acc: 0.9018, Precision: 0.9021, Recall: 0.9018\nTest Loss: 0.6216, Acc: 0.9050, Precision: 0.9050, Recall: 0.9050\nModel saved to model_checkpoints/efficientnet_emotion_epoch_15.pth\n\nEpoch 16/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.20it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 21.00it/s]\nEvaluating: 100%|██████████| 470/470 [00:22<00:00, 21.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0129, Acc: 0.9958, Precision: 0.9958, Recall: 0.9958\nVal Loss: 0.6378, Acc: 0.9021, Precision: 0.9021, Recall: 0.9021\nTest Loss: 0.6342, Acc: 0.9067, Precision: 0.9066, Recall: 0.9067\n\nEpoch 17/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:21<00:00,  8.17it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 20.37it/s]\nEvaluating: 100%|██████████| 470/470 [00:21<00:00, 21.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0119, Acc: 0.9960, Precision: 0.9960, Recall: 0.9960\nVal Loss: 0.6399, Acc: 0.9037, Precision: 0.9040, Recall: 0.9037\nTest Loss: 0.6359, Acc: 0.9058, Precision: 0.9058, Recall: 0.9058\n\nEpoch 18/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:20<00:00,  8.20it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 20.92it/s]\nEvaluating: 100%|██████████| 470/470 [00:22<00:00, 21.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0119, Acc: 0.9960, Precision: 0.9960, Recall: 0.9960\nVal Loss: 0.6386, Acc: 0.9038, Precision: 0.9039, Recall: 0.9038\nTest Loss: 0.6367, Acc: 0.9064, Precision: 0.9063, Recall: 0.9064\n\nEpoch 19/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:21<00:00,  8.17it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 19.94it/s]\nEvaluating: 100%|██████████| 470/470 [00:22<00:00, 21.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0111, Acc: 0.9962, Precision: 0.9962, Recall: 0.9962\nVal Loss: 0.6438, Acc: 0.9029, Precision: 0.9029, Recall: 0.9029\nTest Loss: 0.6450, Acc: 0.9066, Precision: 0.9066, Recall: 0.9066\n\nEpoch 20/20\n----------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1643/1643 [03:21<00:00,  8.17it/s]\nEvaluating: 100%|██████████| 235/235 [00:11<00:00, 20.46it/s]\nEvaluating: 100%|██████████| 470/470 [00:21<00:00, 21.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0103, Acc: 0.9965, Precision: 0.9965, Recall: 0.9965\nVal Loss: 0.6373, Acc: 0.9029, Precision: 0.9032, Recall: 0.9029\nTest Loss: 0.6361, Acc: 0.9063, Precision: 0.9065, Recall: 0.9063\nModel saved to model_checkpoints/efficientnet_emotion_epoch_20.pth\nTraining complete in 78m 14s\n\nMetrics at key epochs:\n\nEpoch 10:\nValidation - Accuracy: 0.9006, Precision: 0.9007, Recall: 0.9006\nTest - Accuracy: 0.8996, Precision: 0.8995, Recall: 0.8996\n\nEpoch 15:\nValidation - Accuracy: 0.9018, Precision: 0.9021, Recall: 0.9018\nTest - Accuracy: 0.9050, Precision: 0.9050, Recall: 0.9050\n\nEpoch 20:\nValidation - Accuracy: 0.9029, Precision: 0.9032, Recall: 0.9029\nTest - Accuracy: 0.9063, Precision: 0.9065, Recall: 0.9063\nTraining completed and metrics saved.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}