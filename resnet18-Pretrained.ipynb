{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.2-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Requirement already satisfied: torch==2.6.0 in c:\\users\\hp\\desktop\\nndl_project\\venv\\lib\\site-packages (from torchvision) (2.6.0+cu124)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\desktop\\nndl_project\\venv\\lib\\site-packages (from torch==2.6.0->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hp\\desktop\\nndl_project\\venv\\lib\\site-packages (from torch==2.6.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\desktop\\nndl_project\\venv\\lib\\site-packages (from torch==2.6.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\desktop\\nndl_project\\venv\\lib\\site-packages (from torch==2.6.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hp\\desktop\\nndl_project\\venv\\lib\\site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\desktop\\nndl_project\\venv\\lib\\site-packages (from torch==2.6.0->torchvision) (3.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\desktop\\nndl_project\\venv\\lib\\site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\desktop\\nndl_project\\venv\\lib\\site-packages (from jinja2->torch==2.6.0->torchvision) (2.1.5)\n",
      "Installing collected packages: pillow, numpy, torchvision\n",
      "Successfully installed numpy-2.2.2 pillow-11.1.0 torchvision-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\HP\\Desktop\\NNDL_Project\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations (ResNet requires specific normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet expects 224x224 images\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "full_train_data = datasets.ImageFolder(root=\"C://Users//HP//Desktop//NNDL_Project//train\", transform=transform)\n",
    "test_data = datasets.ImageFolder(root=\"C://Users//HP//Desktop//NNDL_Project//test\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation split (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(full_train_data))\n",
    "val_size = len(full_train_data) - train_size\n",
    "train_data, val_data = random_split(full_train_data, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\NNDL_Project\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\Desktop\\NNDL_Project\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load Pretrained ResNet18 Model\n",
    "model = models.resnet18(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the last layer for 7 emotion classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(full_train_data.classes))  # 7 output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to GPU if available\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 718/718 [02:10<00:00,  5.49it/s]\n",
      "Validating Epoch 6: 100%|██████████| 180/180 [00:19<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.4361, Val Loss: 1.2710, Val Accuracy: 63.41%, Val Precision: 0.63, Val Recall: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 718/718 [02:07<00:00,  5.64it/s]\n",
      "Validating Epoch 7: 100%|██████████| 180/180 [00:18<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.2768, Val Loss: 1.5561, Val Accuracy: 61.39%, Val Precision: 0.62, Val Recall: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 718/718 [02:35<00:00,  4.63it/s]\n",
      "Validating Epoch 8: 100%|██████████| 180/180 [00:23<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1953, Val Loss: 1.7292, Val Accuracy: 62.07%, Val Precision: 0.62, Val Recall: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 718/718 [02:47<00:00,  4.29it/s]\n",
      "Validating Epoch 9: 100%|██████████| 180/180 [00:28<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.1573, Val Loss: 1.7745, Val Accuracy: 60.71%, Val Precision: 0.62, Val Recall: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 718/718 [02:31<00:00,  4.75it/s]\n",
      "Validating Epoch 10: 100%|██████████| 180/180 [00:27<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.1330, Val Loss: 2.1327, Val Accuracy: 61.42%, Val Precision: 0.63, Val Recall: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 718/718 [02:28<00:00,  4.83it/s]\n",
      "Validating Epoch 11: 100%|██████████| 180/180 [00:19<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 0.1261, Val Loss: 1.8854, Val Accuracy: 61.88%, Val Precision: 0.62, Val Recall: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 718/718 [02:28<00:00,  4.83it/s]\n",
      "Validating Epoch 12: 100%|██████████| 180/180 [00:21<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.1025, Val Loss: 1.9722, Val Accuracy: 61.76%, Val Precision: 0.62, Val Recall: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 718/718 [02:25<00:00,  4.93it/s]\n",
      "Validating Epoch 13: 100%|██████████| 180/180 [00:21<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train Loss: 0.0877, Val Loss: 2.3632, Val Accuracy: 60.55%, Val Precision: 0.61, Val Recall: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 718/718 [02:33<00:00,  4.68it/s]\n",
      "Validating Epoch 14: 100%|██████████| 180/180 [00:21<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Loss: 0.1009, Val Loss: 1.9135, Val Accuracy: 61.29%, Val Precision: 0.63, Val Recall: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 718/718 [02:34<00:00,  4.66it/s]\n",
      "Validating Epoch 15: 100%|██████████| 180/180 [00:23<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train Loss: 0.0842, Val Loss: 2.1555, Val Accuracy: 61.79%, Val Precision: 0.62, Val Recall: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 718/718 [02:32<00:00,  4.71it/s]\n",
      "Validating Epoch 16: 100%|██████████| 180/180 [00:21<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.0730, Val Loss: 2.4136, Val Accuracy: 60.01%, Val Precision: 0.60, Val Recall: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 718/718 [02:37<00:00,  4.55it/s]\n",
      "Validating Epoch 17: 100%|██████████| 180/180 [00:21<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train Loss: 0.0714, Val Loss: 2.1528, Val Accuracy: 62.28%, Val Precision: 0.62, Val Recall: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 718/718 [02:17<00:00,  5.24it/s]\n",
      "Validating Epoch 18: 100%|██████████| 180/180 [00:18<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train Loss: 0.0637, Val Loss: 2.3524, Val Accuracy: 61.60%, Val Precision: 0.63, Val Recall: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 718/718 [02:18<00:00,  5.18it/s]\n",
      "Validating Epoch 19: 100%|██████████| 180/180 [00:18<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train Loss: 0.0677, Val Loss: 2.2556, Val Accuracy: 62.24%, Val Precision: 0.63, Val Recall: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 718/718 [02:25<00:00,  4.93it/s]\n",
      "Validating Epoch 20: 100%|██████████| 180/180 [00:24<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 0.0719, Val Loss: 2.4082, Val Accuracy: 61.67%, Val Precision: 0.61, Val Recall: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Test Set: 100%|██████████| 225/225 [00:29<00:00,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.44%, Test Precision: 0.60, Test Recall: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "\n",
    "import torch\n",
    "\n",
    "# Define the model again (same as before)\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(full_train_data.classes))  # 7 output classes\n",
    "\n",
    "# Load the model's state dict from epoch 5\n",
    "checkpoint_path = \"resnet18_emotion_epoch_5.pth\"\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "# Move the model to the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the optimizer and loss function again (since we need them for training)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Start training from epoch 6\n",
    "start_epoch = 5\n",
    "num_epochs = 20  # Continue training for 10 epochs in total (or adjust as needed)\n",
    "\n",
    "# Training Loop from Epoch 6\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\", total=len(train_loader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Validating Epoch {epoch+1}\", total=len(val_loader)):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate Accuracy, Precision, and Recall\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_precision = precision_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "    val_recall = recall_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "          f\"Val Accuracy: {val_accuracy:.2f}%, Val Precision: {val_precision:.2f}, Val Recall: {val_recall:.2f}\")\n",
    "\n",
    "    # Save model after each epoch\n",
    "    torch.save(model.state_dict(), f\"resnet18_emotion_epoch_{epoch+1}.pth\")\n",
    "\n",
    "# Final Evaluation on Test Set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Evaluating Test Set\", total=len(test_loader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "test_precision = precision_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "test_recall = recall_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%, Test Precision: {test_precision:.2f}, Test Recall: {test_recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\desktop\\nndl_project\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\HP\\Desktop\\NNDL_Project\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
